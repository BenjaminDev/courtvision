{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Court Vision Pipeline\n",
    "### Single Stationary Camera\n",
    "1. Detect lines or corners of court in a single frame of the clip\n",
    "2. Compute the homography between the image and the base world frame\n",
    "3. Make image plane detections. People, Ball etc.\n",
    "4. Project detections onto base world frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from torchvision.io import read_image\n",
    "from courtvision.geometry import (\n",
    "    get_corners_image,\n",
    "    get_coords_world_3d_n,\n",
    "    corners_world_n,\n",
    "    convert_corners_to_vec,\n",
    "    PadelCourt,\n",
    "    compute_homography,\n",
    "    project_points_to_base_plane\n",
    ")\n",
    "from courtvision.geometry import corners_world_3d\n",
    "import numpy as np\n",
    "from courtvision.vis import (\n",
    "    plot_n_images_in_a_grid,\n",
    "    load_timg,\n",
    "    plot_3d_lines,\n",
    "    plot_3d_points,\n",
    "    log_court_layout\n",
    ")\n",
    "from courtvision.swiss import save_camera_params\n",
    "import cv2\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rerun as rr\n",
    "\n",
    "from courtvision.models import get_fasterrcnn_ball_detection_model\n",
    "from courtvision.swiss import get_latest_file\n",
    "from courtvision.trackers import Tracker\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_PLAYER_DETECTION = False\n",
    "RUN_BALL_DETECTION = False\n",
    "RUN_BALL_TRACKER = True\n",
    "\n",
    "COURT_MESH_PATH = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/blender/basic_image.glb\"\n",
    ")\n",
    "\n",
    "CALIBRATION_FILE = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/datasets/calibrations/v1/24_error_11.11_calibration.npz\"\n",
    ")\n",
    "CLIP_DATA_DIR = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/data/frames/curated_001\"\n",
    ")\n",
    "RAW_CLIP_PATH = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/data/raw/curated_001.mp4\"\n",
    ")\n",
    "CLIP_NAME = RAW_CLIP_PATH.stem\n",
    "\n",
    "IMAGE_TO_FLOOR_HOMOGRAPHY_FILE = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/data/frames/curated_001/homography.npy\"\n",
    ")\n",
    "\n",
    "BALL_DETECTOR_DIR = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/models/ball_detector/\"\n",
    ")\n",
    "BALL_DETECTOR_PATH = get_latest_file(BALL_DETECTOR_DIR, \".pt\")\n",
    "BALL_DETECTOR_MODEL_NAME = BALL_DETECTOR_PATH.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PLAYER_DETECTION:\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    model.classes = [0]\n",
    "    model.conf = 0.6\n",
    "    model.max_det = 4\n",
    "    results = model.track(\n",
    "        source=RAW_CLIP_PATH.as_posix(),\n",
    "        # tracker=\"/Users/benjamindecharmoy/projects/courtvision/bytetrack.yaml\",\n",
    "        tracker=\"/Users/benjamindecharmoy/projects/courtvision/botsort.yml\",\n",
    "        classes=[0],\n",
    "        max_det=4,\n",
    "        save=True,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    from pickle import load, dump\n",
    "\n",
    "    results = load(open(\"results.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50., 70.,  5.],\n",
      "        [50., 70.,  5.],\n",
      "        [50., 70.,  5.],\n",
      "        ...,\n",
      "        [50., 70.,  5.],\n",
      "        [50., 70.,  5.],\n",
      "        [50., 70.,  5.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[17064.2383, 23731.7988],\n",
       "        [17064.2383, 23731.7988],\n",
       "        [17064.2383, 23731.7988],\n",
       "        ...,\n",
       "        [17064.2383, 23731.7988],\n",
       "        [17064.2383, 23731.7988],\n",
       "        [17064.2383, 23731.7988]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Trained Ball detection model\n",
    "if RUN_BALL_DETECTION:\n",
    "    ball_detector = get_fasterrcnn_ball_detection_model(BALL_DETECTOR_PATH).eval()\n",
    "\n",
    "if RUN_BALL_TRACKER:\n",
    "    tracker = Tracker(\n",
    "        num_particles=1000,\n",
    "        world_to_cam=torch.tensor(np.load(CALIBRATION_FILE)[\"camera_matrix\"]),\n",
    "        court_size=torch.tensor(\n",
    "            [PadelCourt.width, PadelCourt.length, PadelCourt.backall_fence_height]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "from courtvision.trackers import StateIdx\n",
    "from courtvision.geometry import (\n",
    "    convert_points_to_homogeneous,\n",
    "    convert_points_from_homogeneous,\n",
    ")\n",
    "\n",
    "#  def state_to_observation(state, H):\n",
    "x_y_z_1_positions = tracker.states[:, : StateIdx.z + 1].rename(None)\n",
    "print(x_y_z_1_positions)\n",
    "convert_points_from_homogeneous((tracker.H @ x_y_z_1_positions.T).T)\n",
    "\n",
    "\n",
    "# tracker.likelihood(obs_state=torch.tensor([100,100]),pred_state=tracker.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  89.2775,   41.5601,   73.1566],\n",
       "        [ 104.1247, -189.6820,   29.2836],\n",
       "        [ 173.9896,   53.6179,  106.1288],\n",
       "        ...,\n",
       "        [  14.9235,  -94.6962,   51.7571],\n",
       "        [  10.8966, -142.5561,  -13.8988],\n",
       "        [  19.8083,  231.7995,   26.1076]], names=('num_particles', 'state'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-06T17:38:13Z WARN  rerun::run] Failed to bind TCP address \"0.0.0.0:9876\". Another Rerun instance is probably running.\n",
      "[2023-06-06T17:38:13Z WARN  re_renderer::importer::gltf] Textures on meshes are always sampled repeating address mode.\n",
      "     exture None had ClampToEdge for s wrapping and ClampToEdge for t wrapping, these settings will be ignored\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from kornia import image_to_tensor\n",
    "from datetime import datetime\n",
    "\n",
    "player_maker_radius = 5.0\n",
    "base_results = defaultdict(list)\n",
    "if not RUN_BALL_DETECTION:\n",
    "    ball_detection_resullt = load(open(\"ball_detection_resullt.pkl\", \"rb\"))\n",
    "else:\n",
    "    ball_detection_resullt = []\n",
    "rr.init(\n",
    "    f\"{CLIP_NAME}-{BALL_DETECTOR_MODEL_NAME}-{datetime.now()}\", spawn=True\n",
    ")  # Spawn a Rerun Viewer and stream log events to it\n",
    "\n",
    "colours_per_idx = defaultdict(lambda: (255, 255, 255))\n",
    "colours_per_idx.update(\n",
    "    {\n",
    "        0: (0, 255, 0),\n",
    "        1: (0, 0, 255),\n",
    "        2: (255, 0, 0),\n",
    "        3: (255, 255, 0),\n",
    "        4: (255, 0, 255),\n",
    "        5: (0, 255, 255),\n",
    "    }\n",
    ")\n",
    "log_court_layout(\n",
    "    camera_matrix=np.load(CALIBRATION_FILE)[\"camera_matrix\"],\n",
    "    image_width=results[0].orig_img.shape[1],\n",
    "    image_height=results[0].orig_img.shape[0],\n",
    "    court_mesh_path=COURT_MESH_PATH,\n",
    "    translation_vector=np.load(CALIBRATION_FILE)[\"translation_vector\"],\n",
    "    rotation_vector=np.load(CALIBRATION_FILE)[\"rotation_vector\"],\n",
    ")\n",
    "H = np.load(IMAGE_TO_FLOOR_HOMOGRAPHY_FILE)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    # Start streaming results to the Rerun Viewer\n",
    "    rr.set_time_sequence(\"play\", i)\n",
    "    if RUN_BALL_DETECTION:\n",
    "        with torch.no_grad():\n",
    "            outputs = ball_detector(\n",
    "                image_to_tensor(result.orig_img, keepdim=False).float() / 255.0,\n",
    "            )\n",
    "        ball_detection_resullt.append(outputs)\n",
    "        dump(ball_detection_resullt, open(\"ball_detection_resullt.pkl\", \"wb\"))\n",
    "    else:\n",
    "        outputs = ball_detection_resullt[i]\n",
    "\n",
    "    # Ball Tracker Goes here!!\n",
    "    if RUN_BALL_TRACKER:\n",
    "        rr.log_points(\n",
    "            \"world/ball_state\",\n",
    "            positions=tracker.xyz,\n",
    "        )\n",
    "    if outputs and len(outputs[0][\"boxes\"]) > 0:\n",
    "        for bx1, by1, bx2, by2 in outputs[0][\"boxes\"][:4]:\n",
    "            # bx1, by1, bx2, by2 = outputs[0][\"boxes\"][0]\n",
    "            rr.log_rect(\n",
    "                f\"world/camera/image/Ball\",\n",
    "                (bx1, by1, bx2 - bx1, by2 - by1),\n",
    "                color=colours_per_idx[-1],\n",
    "            )\n",
    "    rr.log_image(\"world/camera/image\", result.orig_img)\n",
    "\n",
    "    for det in result.boxes.data:\n",
    "        x1, y1, x2, y2, idx, conf, cls = det\n",
    "        rr.log_rect(\n",
    "            f\"world/camera/image/Player_{int(idx)}\",\n",
    "            (x1, y1, (x2 - x1), (y2 - y1)),\n",
    "            color=colours_per_idx[int(idx)],\n",
    "        )\n",
    "        mid_feet = torch.tensor([((x1 + x2) / 2, (y2 + y2) / 2)])\n",
    "        (mid_feet_base,) = project_points_to_base_plane(points=mid_feet, H=H)\n",
    "\n",
    "        mid_feet_base_3d = (\n",
    "            F.pad(mid_feet_base, (0, 1), mode=\"constant\", value=0.0) / 10.0\n",
    "        )\n",
    "        # Switch Y and Z axis\n",
    "        x = mid_feet_base_3d[0].item()\n",
    "        y = mid_feet_base_3d[1].item()\n",
    "        z = mid_feet_base_3d[2].item()\n",
    "        mid_feet_base_3d[2] = player_maker_radius\n",
    "        mid_feet_base_3d[1] = 200.0 - y\n",
    "        mid_feet_base_3d[0] = x\n",
    "        rr.log_point(\n",
    "            f\"world/Player_{int(idx)}\",\n",
    "            mid_feet_base_3d,\n",
    "            radius=player_maker_radius,\n",
    "            color=colours_per_idx[int(idx)],\n",
    "        )\n",
    "\n",
    "        # base_results[f\"{int(idx)}_xs\"].append(mid_feet_base[0].item())\n",
    "        # base_results[f\"{int(idx)}_ys\"].append(mid_feet_base[1].item())\n",
    "        # base_results[f\"{int(idx)}_zs\"].append(0.0)\n",
    "        # base_results[f\"{int(idx)}_conf\"].append(conf.item())\n",
    "\n",
    "    # if i > 10:\n",
    "    #     break\n",
    "\n",
    "    # break\n",
    "# plt.imshow(image)\n",
    "# results[0].boxes.boxes, results[0].boxes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m dd\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[39m# F.pad(dd, ( 0,1), mode=\"constant\", value=0.0)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# swap y and z\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m torch\u001b[39m.\u001b[39;49mswapdims(dd, \u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m dd\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "dd = torch.tensor([1, 2, 3])\n",
    "# F.pad(dd, ( 0,1), mode=\"constant\", value=0.0)\n",
    "# swap y and z\n",
    "torch.swapdims(dd, 1, 2)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_court_frontwall_markings():\n",
    "    outer_lines = np.array(\n",
    "        [\n",
    "            # Outer lines\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "            corners_world_3d[\"b_front_right\"],\n",
    "            corners_world_3d[\"n_top_front_right\"],\n",
    "            corners_world_3d[\"m_top_front_left\"],\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    x_offset = 3 * 100.0\n",
    "    z_offset = 5 * 100.0\n",
    "    play_boundary = np.array(\n",
    "        [\n",
    "            # Outer lines\n",
    "            (\n",
    "                corners_world_3d[\"a_front_left\"][0] - x_offset,\n",
    "                corners_world_3d[\"a_front_left\"][1],\n",
    "                corners_world_3d[\"a_front_left\"][2],\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"b_front_right\"][0] + x_offset,\n",
    "                corners_world_3d[\"b_front_right\"][1],\n",
    "                corners_world_3d[\"b_front_right\"][2],\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"n_top_front_right\"][0] + x_offset,\n",
    "                corners_world_3d[\"n_top_front_right\"][1],\n",
    "                corners_world_3d[\"n_top_front_right\"][2] + z_offset,\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"m_top_front_left\"][0] - x_offset,\n",
    "                corners_world_3d[\"m_top_front_left\"][1],\n",
    "                corners_world_3d[\"m_top_front_left\"][2] + z_offset,\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"a_front_left\"][0] - x_offset,\n",
    "                corners_world_3d[\"a_front_left\"][1],\n",
    "                corners_world_3d[\"a_front_left\"][2],\n",
    "            ),\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    xs = np.array([outer_lines[:-1, 0], outer_lines[1:, 0]]).T\n",
    "    xs = np.append(\n",
    "        xs, np.array([play_boundary[:-1, 0], play_boundary[1:, 0]]).T, axis=0\n",
    "    )\n",
    "\n",
    "    ys = np.array([outer_lines[:-1, 1], outer_lines[1:, 1]]).T\n",
    "    ys = np.append(\n",
    "        ys, np.array([play_boundary[:-1, 1], play_boundary[1:, 1]]).T, axis=0\n",
    "    )\n",
    "\n",
    "    zs = np.array([outer_lines[:-1, 2], outer_lines[1:, 2]]).T\n",
    "    zs = np.append(\n",
    "        zs, np.array([play_boundary[:-1, 2], play_boundary[1:, 2]]).T, axis=0\n",
    "    )\n",
    "\n",
    "    return xs, ys, zs\n",
    "\n",
    "\n",
    "xs, ys, zs = get_court_frontwall_markings()\n",
    "plt_axis, fig = plot_3d_lines(xs=xs, ys=ys, zs=zs, view_init=(0, 90, 0))\n",
    "plt_axis.set_title(\"\")\n",
    "plt_axis.set_xlabel(\"\")\n",
    "plt_axis.set_ylabel(\"\")\n",
    "plt_axis.set_xticks([])\n",
    "plt_axis.set_yticks([])\n",
    "plt_axis.set_zticks([])\n",
    "plt_axis.spines[\"right\"].set_visible(False)\n",
    "plt_axis.spines[\"top\"].set_visible(False)\n",
    "plt_axis.spines[\"bottom\"].set_visible(False)\n",
    "plt_axis.spines[\"left\"].set_visible(False)\n",
    "plt.axis(\"off\")\n",
    "plt.axis(\"image\")\n",
    "plt.savefig(\"frontwall.png\", bbox_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_world_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_court_markings():\n",
    "    outer_lines = np.array(\n",
    "        [\n",
    "            # Outer lines\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "            corners_world_3d[\"b_front_right\"],\n",
    "            corners_world_3d[\"d_back_right\"],\n",
    "            corners_world_3d[\"c_back_left\"],\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    inner_lines = np.array(\n",
    "        [\n",
    "            corners_world_3d[\"e_left_near_serve_line\"],\n",
    "            corners_world_3d[\"f_right_near_serve_line\"],\n",
    "            corners_world_3d[\"h_right_far_serve_line\"],\n",
    "            corners_world_3d[\"g_left_far_serve_line\"],\n",
    "            corners_world_3d[\"e_left_near_serve_line\"],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    center_line = np.array(\n",
    "        [\n",
    "            corners_world_3d[\"k_center_line_near\"],\n",
    "            corners_world_3d[\"i_center_line_far\"],\n",
    "        ]\n",
    "    )\n",
    "    net_line = np.array(\n",
    "        [\n",
    "            corners_world_3d[\"j_net_line_left\"],\n",
    "            corners_world_3d[\"l_net_line_right\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    xs = np.array([outer_lines[:-1, 0], outer_lines[1:, 0]]).T\n",
    "    xs = np.append(xs, np.array([inner_lines[:-1, 0], inner_lines[1:, 0]]).T, axis=0)\n",
    "    xs = np.append(xs, np.array([center_line[:-1, 0], center_line[1:, 0]]).T, axis=0)\n",
    "    xs = np.append(xs, np.array([net_line[:-1, 0], net_line[1:, 0]]).T, axis=0)\n",
    "\n",
    "    ys = np.array([outer_lines[:-1, 1], outer_lines[1:, 1]]).T\n",
    "    ys = np.append(ys, np.array([inner_lines[:-1, 1], inner_lines[1:, 1]]).T, axis=0)\n",
    "    ys = np.append(ys, np.array([center_line[:-1, 1], center_line[1:, 1]]).T, axis=0)\n",
    "    ys = np.append(ys, np.array([net_line[:-1, 1], net_line[1:, 1]]).T, axis=0)\n",
    "\n",
    "    zs = np.array([outer_lines[:-1, 2], outer_lines[1:, 2]]).T\n",
    "    zs = np.append(zs, np.array([inner_lines[:-1, 2], inner_lines[1:, 2]]).T, axis=0)\n",
    "    zs = np.append(zs, np.array([center_line[:-1, 2], center_line[1:, 2]]).T, axis=0)\n",
    "    zs = np.append(zs, np.array([net_line[:-1, 2], net_line[1:, 2]]).T, axis=0)\n",
    "\n",
    "    return xs, ys, zs\n",
    "\n",
    "\n",
    "xs, ys, zs = get_court_markings()\n",
    "plt_axis, fig = plot_3d_lines(xs=xs, ys=ys, zs=zs, view_init=(90, 90, 0))\n",
    "from courtvision.vis import plot_3d_points\n",
    "\n",
    "idx = 1\n",
    "# xs = np.array(base_results[f\"{idx}_xs\"])\n",
    "# ys = np.array(base_results[f\"{idx}_ys\"])\n",
    "# zs = np.array(base_results[f\"{idx}_zs\"])\n",
    "plt_axis.set_title(\"\")\n",
    "plt_axis.set_xlabel(\"\")\n",
    "plt_axis.set_ylabel(\"\")\n",
    "plt_axis.set_xticks([])\n",
    "plt_axis.set_yticks([])\n",
    "plt_axis.set_zticks([])\n",
    "plt_axis.spines[\"right\"].set_visible(False)\n",
    "plt_axis.spines[\"top\"].set_visible(False)\n",
    "plt_axis.spines[\"bottom\"].set_visible(False)\n",
    "plt_axis.spines[\"left\"].set_visible(False)\n",
    "# plot_3d_lines\n",
    "plt.axis(\"off\")\n",
    "plt.axis(\"image\")\n",
    "plt_axis.margins(x=0)\n",
    "plt.savefig(\"test.png\", bbox_inches=0)\n",
    "\n",
    "# plt_axis, _=plot_3d_points(x=xs, y=ys, z=zs, plt_axis=plt_axis ,view_init=(90, 90,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.log(\"test\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from courtvision.vis import plot_3d_points, plot_3d_lines\n",
    "from courtvision.geometry import get_coords_world_3d\n",
    "import numpy as np\n",
    "\n",
    "court_markings = get_coords_world_3d()\n",
    "xs = np.array([court_markings[:1, 0], court_markings[1:2, 0]]).T\n",
    "xs = np.append(xs, np.array([court_markings[1:2, 0], court_markings[3:4, 0]]).T, axis=0)\n",
    "xs = np.append(xs, np.array([court_markings[3:4, 0], court_markings[4:5, 0]]).T, axis=0)\n",
    "xs = np.append(xs, np.array([court_markings[4:5, 0], court_markings[:1, 0]]).T, axis=0)\n",
    "\n",
    "ys = np.array([court_markings[:-1, 1], court_markings[1:, 1]]).T\n",
    "zs = np.array([court_markings[:-1, 2], court_markings[1:, 2]]).T\n",
    "plot_3d_lines(xs=xs, ys=ys, zs=zs)\n",
    "# get_coords_world_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
