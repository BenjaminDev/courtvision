@article{BacligMaria,
   abstract = {Sports pose a unique challenge for high-speed, unobtrusive, uninterrupted motion tracking due to speed of movement and player occlusion, especially in the fast and competitive sport of squash. The objective of this study is to use video tracking techniques to quantify kinematics in elite-level squash. With the increasing availability and quality of elite tournament matches filmed for entertainment purposes, a new methodology of multi-player tracking for squash that only requires broadcast video as an input is proposed. This paper introduces and evaluates a markerless motion capture technique using an autonomous deep learning based human pose estimation algorithm and computer vision to detect and identify players. Inverse perspective mapping is utilized to convert pixel coordinates to court coordinates and distance traveled, court position, ‘T’ dominance, and average speeds of elite players in squash is determined. The method was validated using results from a previous study using manual tracking where the proposed method (filtered coordinates) displayed an average absolute percent error to the manual approach of 3.73% in total distance traveled, 3.52% and 1.26% in average speeds <9 m/s with and without speeds <1 m/s, respectively. The method has proven to be the most effective in collecting kinematic data of elite players in squash in a timely manner with no special camera setup and limited manual intervention.},
   author = {Maria Martine Baclig and Noah Ergezinger and Qipei Mei and Mustafa Gül and Samer Adeeb and Lindsey Westover},
   doi = {10.3390/app10248793},
   issn = {20763417},
   issue = {24},
   journal = {Applied Sciences (Switzerland)},
   keywords = {Kinematics,Player identification,Racquet sports,Sports broadcast analysis,Video tracking},
   month = {12},
   pages = {1-16},
   publisher = {MDPI AG},
   title = {A deep learning and computer vision based multi-player tracker for squash},
   volume = {10},
   year = {2020},
}
@report{HanJungong,
   abstract = {In this paper, we present a generic 3-D modeling for analyzing court-net sports videos, which enables to map points in the real-world coordinates to the image coordinates. To this end, we propose a two-step algorithm to extract the feature lines and points from two perpendicular planes (ground and net plane) for determining the camera calibration parameters. In the first step, we bridge the gap between the 2-D standard court model and the image coordinate system that is described by a plane-to-plane mapping. With this mapping, it is possible to distinguish the feature lines like court lines in the ground plane. The second step is to detect the net line located in the net plane, where the line is classified as net line if it passes several tests. The feature points at well-known positions within these two planes (e.g. intersection of two lines) are utilized to calculate the camera calibration parameters. We demonstrate the performance of the proposed algorithm by evaluating it for a variety of court-net sports videos including badminton, tennis and volleyball. Results show that the algorithm is robust to partial court views or bad lighting conditions, and can be applied to various applications.},
   author = {Jungong Han and Dirk Farin and Peter H N De With},
   keywords = {3-D modeling,Content analysis,Generic,Sports video},
   title = {Generic 3-D Modeling for Content Analysis of Court-Net Sports Sequences},
}
@article{JavadihaMohammadreza,
   abstract = {The estimation of player positions is key for performance analysis in sport. In this paper, we focus on image-based, single-angle, player position estimation in padel. Unlike tennis, the primary camera view in professional padel videos follows a de facto standard, consisting of a high-angle shot at about 7.6 m above the court floor. This camera angle reduces the occlusion impact of the mesh that stands over the glass walls, and offers a convenient view for judging the depth of the ball and the player positions and poses. We evaluate and compare the accuracy of state-of-the-art computer vision methods on a large set of images from both amateur videos and publicly available videos from the major international padel circuit. The methods we analyze include object detection, image segmentation and pose estimation techniques, all of them based on deep convolutional neural networks. We report accuracy and average precision with respect to manually-annotated video frames. The best results are obtained by top-down pose estimation methods, which offer a detection rate of 99.8% and a RMSE below 5 and 12 cm for horizontal/vertical court-space coordinates (deviations from predicted and ground-truth player positions). These results demonstrate the suitability of pose estimation methods based on deep convolutional neural networks for estimating player positions from single-angle padel videos. Immediate applications of this work include the player and team analysis of the large collection of publicly available videos from international circuits, as well as an inexpensive method to get player positional data in amateur padel clubs.},
   author = {Mohammadreza Javadiha and Carlos Andujar and Enrique Lacasa and Angel Ric and Antonio Susin},
   doi = {10.3390/s21103368},
   issn = {14248220},
   issue = {10},
   journal = {Sensors},
   keywords = {Deep learning,Player tracking,Pose estimation,Racket sports,Sports science,Tracking data},
   month = {5},
   pmid = {34066162},
   publisher = {MDPI AG},
   title = {Estimating player positions from padel high-angle videos: Accuracy comparison of recent computer vision methods},
   volume = {21},
   year = {2021},
}
@article{KrizkovaSarka2021,
   abstract = {Athletes, both professional and amateur, are always looking for ways to improve their performance. With the introduction and increasing availability of modern technologies and smart devices arose the need to measure and analyze performance, but likewise, the use of these innovations as a competitive advantage also arose. Scientific publications reflect the wide range of available approaches and technologies, as well as the growing interest in various sports. As a result, we concentrated on a systematic review of publications that presented performance analysis tools and methods in all sports, with a final focus on racket sports. Clarivate Analytics’ Web of Science (WoS) and Elsevier Inc.’s SCOPUS databases were searched for 1147 studies that conducted performance analysis and sports research and were published in English. The data in the systematic review are current, up until 18 May 2021. A general review was performed on 759 items, and then 65 racket sports publications were thoroughly scrutinized. We concentrated on performance data, data collection and analysis tools, performance analysis methods, and software. We also talked about performance prediction. In performance research, we have identified specific approaches for specific sports as well as key countries. We are also considering expanding performance analysis in to E-sports in the future.},
   author = {Sarka Krizkova and Hana Tomaskova and Erfan Babaee Tirkolaee},
   doi = {10.3390/app11199212},
   issn = {20763417},
   issue = {19},
   journal = {Applied Sciences (Switzerland)},
   keywords = {Performance analysis,Racket sports,Sports,Systematic review},
   month = {10},
   publisher = {MDPI},
   title = {Sport performance analysis with a focus on racket sports: A review},
   volume = {11},
   year = {2021},
}
@report{LongSha,
   abstract = {The increasing number of vision-based tracking systems deployed in production has necessitated fast, robust camera calibration. In the domain of sport, the majority of current work focuses on sports where lines and intersections are easy to extract, and appearance is relatively consistent across venues. However, for more challenging sports like basketball, those techniques are not sufficient. In this paper, we propose an end-to-end approach for single moving camera calibration across challenging scenarios in sports. Our method contains three key modules: 1) area-based court segmentation, 2) camera pose estimation with embedded templates, 3) homography prediction via a spatial transform network (STN). All three modules are connected, enabling end-to-end training. We evaluate our method on a new college basketball dataset and demonstrate the state of the art performance in variable and dynamic environments. We also validate our method on the World Cup 2014 dataset to show its competitive performance against the state-of-the-art methods. Lastly, we show that our method is two orders of magnitude faster than the previous state of the art on both datasets.},
   author = {Long Sha Jennifer Hobbs Panna Felsen Xinyu Wei Patrick Lucey Sujoy Ganguly},
   title = {End-to-End Camera Calibration for Broadcast Videos},
}
@report{LiuPaul,
   abstract = {Trajectory estimation is a fundamental component of racket sport analytics, as the trajectory contains information not only about the winning and losing of each point, but also how it was won or lost. In sports such as badminton, players benefit from knowing the full 3D trajectory, as the height of shuttlecock or ball provides valuable tactical information. Unfortunately, 3D reconstruction is a notoriously hard problem, and standard trajectory estimators can only track 2D pixel coordinates. In this work, we present the first complete end-to-end system for the extraction and segmentation of 3D shuttle trajectories from monocular badminton videos. Our system integrates badminton domain knowledge such as court dimension, shot placement, physical laws of motion, along with vision-based features such as player poses and shuttle tracking. We find that significant engineering efforts and model improvements are needed to make the overall system robust, and as a by-product of our work, improve state-of-the-art results on court recognition, 2D trajectory estimation, and hit recognition.},
   author = {Paul Liu and Jui-Hsien Wang Adobe Seattle},
   title = {MonoTrack: Shuttle trajectory reconstruction from monocular badminton video},
}
@report{VanZandycke,
   abstract = {Ball 3D localization in team sports has various applications including automatic offside detection in soccer, or shot release localization in basketball. Today, this task is either resolved by using expensive multi-views setups, or by restricting the analysis to ballistic trajectories. In this work, we propose to address the task on a single image from a calibrated monocular camera by estimating ball diameter in pixels and use the knowledge of real ball diameter in meters. This approach is suitable for any game situation where the ball is (even partly) visible. To achieve this, we use a small neural network trained on image patches around candidates generated by a conventional ball detector. Besides predicting ball diameter, our network outputs the confidence of having a ball in the image patch. Validations on 3 basketball datasets reveals that our model gives remarkable predictions on ball 3D localization. In addition, through its confidence output, our model improves the detection rate by filtering the candidates produced by the detector. The contributions of this work are (i) the first model to address 3D ball localization on a single image, (ii) an effective method for ball 3D annotation from single calibrated images, (iii) a high quality 3D ball evaluation dataset annotated from a single viewpoint. In addition, the code to reproduce this research will be made freely available at https://github.com/gabriel-vanzandycke/ deepsport},
   author = {Gabriel Van Zandycke and Christophe De Vleeschouwer},
   title = {3D Ball Localization From A Single Calibrated Image},
   url = {https://github.com/gabriel-vanzandycke/},
}
@article{Riba2019,
   abstract = {This work presents Kornia -- an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. The package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.},
   author = {Edgar Riba and Dmytro Mishkin and Daniel Ponsa and Ethan Rublee and Gary Bradski},
   month = {10},
   title = {Kornia: an Open Source Differentiable Computer Vision Library for PyTorch},
   url = {http://arxiv.org/abs/1910.02190},
   year = {2019},
}
@report{pytorch,
   abstract = {In this article, we describe an automatic differentiation module of PyTorch-a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
   author = {Adam Paszke and Sam Gross and Soumith Chintala and Gregory Chanan and Edward Yang and Zachary Devito Facebook and A I Research and Zeming Lin and Alban Desmaison and Luca Antiga and Orobix Srl and Adam Lerer},
   title = {Automatic differentiation in PyTorch},
}
@report{court_dimensions,
   author = {LTA},
   title = {LTA PADEL COURT DATA SHEET},
   url = {https://www.lta.org.uk/4ad2a4/siteassets/play/padel/file/lta-padel-court-guidance.pdf},
}
@misc{LabelStudio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/heartexlabs/label-studio},
  note={Open source software available from https://github.com/heartexlabs/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2022},
}

@software{Jocher_YOLO_by_Ultralytics_2023,
author = {Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
license = {AGPL-3.0},
month = jan,
title = {{YOLO by Ultralytics}},
url = {https://github.com/ultralytics/ultralytics},
version = {8.0.0},
year = {2023}
}
@article{Ren2015,
   abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
   author = {Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},
   month = {6},
   title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
   url = {http://arxiv.org/abs/1506.01497},
   year = {2015},
}

@software{de_Charmoy_CourtVision_2023,
author = {de Charmoy, Benjamin},
doi = {na},
url = {benjamindev.github.io/courtvision}
month = jun,
title = {{CourtVision}},
version = {0.1.0},
year = {2023}
}

@article{Doucet2011,
   abstract = {Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented},
   author = {Arnaud Doucet and Am Johansen},
   doi = {10.1.1.157.772},
   isbn = {978-0199532902},
   issn = {01677152},
   issue = {December},
   journal = {Handbook of Nonlinear Filtering},
   pages = {656-704},
   title = {A tutorial on particle filtering and smoothing: fifteen years later},
   url = {http://automatica.dei.unipd.it/tl_files/utenti/lucaschenato/Classes/PSC10_11/Tutorial_PF_doucet_johansen.pdf},
   year = {2011},
}
@article{Zhang2002,
   abstract = {We propose a flexible new technique to easily calibrate a camera. It is well suited for use without specialized knowledge of 3D geometry or computer vision. The technique only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique, and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthog- onal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one step from laboratory environments to real world use.},
   author = {Zhengyou Zhang},
   doi = {10.1109/34.888718},
   isbn = {MSR-TR-98-71},
   issn = {01628828},
   issue = {11},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   pages = {1330-1334},
   pmid = {131},
   title = {A Flexible New Technique for Camera Calibration (Technical Report)},
   volume = {22},
   year = {2002},
}
@book{Hartley:2003:MVG:861369,
  added-at = {2012-09-23T11:04:02.000+0200},
  address = {New York, NY, USA},
  author = {Hartley, Richard and Zisserman, Andrew},
  biburl = {https://www.bibsonomy.org/bibtex/24867b22ef159cc28fc1bbe1476a0ec57/daill},
  description = {Multiple View Geometry in Computer Vision},
  edition = 2,
  interhash = {7894893cb1baf364de16c2d27541e4c4},
  intrahash = {4867b22ef159cc28fc1bbe1476a0ec57},
  isbn = {0521540518},
  keywords = {geometry multiple view zisserman},
  publisher = {Cambridge University Press},
  timestamp = {2012-09-23T11:04:02.000+0200},
  title = {Multiple View Geometry in Computer Vision},
  year = 2003
}
