{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Court Vision Pipeline\n",
    "### Single Stationary Camera\n",
    "1. Detect lines or corners of court in a single frame of the clip\n",
    "2. Compute the homography between the image and the base world frame\n",
    "3. Make image plane detections. People, Ball etc.\n",
    "4. Project detections onto base world frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from torchvision.io import read_image\n",
    "from courtvision.geometry import (\n",
    "    get_corners_image,\n",
    "    get_coords_world_3d_n,\n",
    "    corners_world_n,\n",
    "    convert_corners_to_vec,\n",
    "    PadelCourt,\n",
    "    compute_homography,\n",
    "    project_points_to_base_plane\n",
    ")\n",
    "from courtvision.geometry import corners_world_3d\n",
    "import numpy as np\n",
    "from courtvision.vis import (\n",
    "    plot_n_images_in_a_grid,\n",
    "    load_timg,\n",
    "    plot_3d_lines,\n",
    "    plot_3d_points,\n",
    "    log_court_layout\n",
    ")\n",
    "from courtvision.swiss import save_camera_params\n",
    "import cv2\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rerun as rr\n",
    "\n",
    "from courtvision.models import get_fasterrcnn_ball_detection_model\n",
    "from courtvision.swiss import get_latest_file\n",
    "from courtvision.trackers import Tracker, StateIdx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_PLAYER_DETECTION = False\n",
    "RUN_BALL_DETECTION = False\n",
    "RUN_BALL_TRACKER = True\n",
    "\n",
    "COURT_MESH_PATH = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/blender/basic_image.glb\"\n",
    ")\n",
    "\n",
    "CALIBRATION_FILE = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/datasets/calibrations/v1/24_error_11.11_calibration.npz\"\n",
    ")\n",
    "CLIP_DATA_DIR = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/data/frames/curated_001\"\n",
    ")\n",
    "RAW_CLIP_PATH = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/data/raw/curated_001.mp4\"\n",
    ")\n",
    "CLIP_NAME = RAW_CLIP_PATH.stem\n",
    "\n",
    "IMAGE_TO_FLOOR_HOMOGRAPHY_FILE = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/data/frames/curated_001/homography.npy\"\n",
    ")\n",
    "\n",
    "BALL_DETECTOR_DIR = Path(\n",
    "    \"/Users/benjamindecharmoy/projects/courtvision/models/ball_detector/\"\n",
    ")\n",
    "BALL_DETECTOR_PATH = get_latest_file(BALL_DETECTOR_DIR, \".pt\")\n",
    "BALL_DETECTOR_MODEL_NAME = BALL_DETECTOR_PATH.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_PLAYER_DETECTION:\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    model.classes = [0]\n",
    "    model.conf = 0.6\n",
    "    model.max_det = 4\n",
    "    results = model.track(\n",
    "        source=RAW_CLIP_PATH.as_posix(),\n",
    "        # tracker=\"/Users/benjamindecharmoy/projects/courtvision/bytetrack.yaml\",\n",
    "        tracker=\"/Users/benjamindecharmoy/projects/courtvision/botsort.yml\",\n",
    "        classes=[0],\n",
    "        max_det=4,\n",
    "        save=True,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    from pickle import load, dump\n",
    "\n",
    "    results = load(open(\"results.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rerun:Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/c10/core/TensorImpl.h:1791.)\n"
     ]
    }
   ],
   "source": [
    "# Load Trained Ball detection model\n",
    "if RUN_BALL_DETECTION:\n",
    "    ball_detector = get_fasterrcnn_ball_detection_model(BALL_DETECTOR_PATH).eval()\n",
    "\n",
    "if RUN_BALL_TRACKER:\n",
    "    rotation_vector = np.load(CALIBRATION_FILE)[\"rotation_vector\"]\n",
    "    translation_vector = np.load(CALIBRATION_FILE)[\"translation_vector\"]\n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    world_to_cam = torch.tensor(\n",
    "        np.vstack(\n",
    "            [np.hstack((rotation_matrix, translation_vector)), np.array([0, 0, 0, 1])]\n",
    "        )\n",
    "    )\n",
    "    tracker = Tracker(\n",
    "        num_particles=1000,\n",
    "        world_to_cam=world_to_cam,\n",
    "        cam_to_image=torch.tensor(np.load(CALIBRATION_FILE)[\"camera_matrix\"]),\n",
    "        court_size=torch.tensor(\n",
    "            [PadelCourt.width, PadelCourt.length, PadelCourt.backall_fence_height]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker.state_to_observation(\n",
    "#     tracker.states, world_to_cam=tracker.world_to_cam, cam_to_image=tracker.cam_to_image\n",
    "# )\n",
    "\n",
    "# from courtvision.trackers import StateIdx\n",
    "# from courtvision.geometry import (\n",
    "#     convert_points_to_homogeneous,\n",
    "#     convert_points_from_homogeneous,\n",
    "# )\n",
    "\n",
    "# # pred_obs = tracker.state_to_observation(\n",
    "# #     tracker.states,\n",
    "# #     world_to_cam=tracker.world_to_cam,\n",
    "# #     cam_to_image=tracker.cam_to_image\n",
    "# # )\n",
    "# # print(pred_obs.shape)\n",
    "# obs_state=torch.tensor([161, 600]).to(dtype=torch.float32)\n",
    "# # obs_state = obs_state.expand_as(pred_obs)\n",
    "# # print(obs_state)\n",
    "# while True:\n",
    "\n",
    "#     tracker.predict(dt=1 / 30.0)\n",
    "#     tracker.update(obs_state=obs_state)\n",
    "#     print(tracker.mean_image_plane_prediction)\n",
    "# #  def state_to_observation(state, H):\n",
    "# # x_y_z_1_positions = convert_points_to_homogeneous(tracker.states[:, : StateIdx.z + 1].rename(None))\n",
    "# # x_y_z_1_positions_cam = convert_points_from_homogeneous(x_y_z_1_positions @ tracker.world_to_cam.T)\n",
    "# # # convert_points_from_homogeneous(x_y_z_1_positions_cam@tracker.cam_to_image.T)\n",
    "\n",
    "# # from kornia.geometry import camera as KCamera\n",
    "# # KCamera.perspective.project_points(\n",
    "# #     x_y_z_1_positions_cam, tracker.cam_to_image\n",
    "# # )\n",
    "# # # convert_points_from_homogeneous((tracker.H @ x_y_z_1_positions.T).T)\n",
    "\n",
    "\n",
    "# # tracker.likelihood(obs_state=torch.tensor([100,100]),pred_state=tracker.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -42.2685,  154.5930,   37.7244],\n",
       "        [ -14.9009,  169.8299,   59.3938],\n",
       "        [ 117.3501, -184.2068,    7.9949],\n",
       "        ...,\n",
       "        [  82.3916,  -15.8381,   92.1844],\n",
       "        [  72.6018,  415.9514,   66.0213],\n",
       "        [ 117.6842,  173.9863,  -60.5210]], names=('num_particles', 'state'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-14T13:10:45Z WARN  eframe::epi] Failed to decode RON: 1:340: Unexpected missing field `kind` in `StoreId`\n",
      "[2023-06-14T13:10:47Z WARN  re_renderer::importer::gltf] Textures on meshes are always sampled repeating address mode.\n",
      "     exture None had ClampToEdge for s wrapping and ClampToEdge for t wrapping, these settings will be ignored\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from kornia import image_to_tensor\n",
    "from datetime import datetime\n",
    "\n",
    "player_maker_radius = 5.0\n",
    "base_results = defaultdict(list)\n",
    "if not RUN_BALL_DETECTION:\n",
    "    ball_detection_resullt = load(open(\"ball_detection_resullt.pkl\", \"rb\"))\n",
    "else:\n",
    "    ball_detection_resullt = []\n",
    "\n",
    "if RUN_BALL_TRACKER:\n",
    "    tracker = Tracker(\n",
    "        num_particles=1000,\n",
    "        world_to_cam=world_to_cam,\n",
    "        cam_to_image=torch.tensor(np.load(CALIBRATION_FILE)[\"camera_matrix\"]),\n",
    "        court_size=torch.tensor(\n",
    "            [PadelCourt.width, PadelCourt.length, PadelCourt.backall_fence_height]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "rr.init(\n",
    "    f\"{CLIP_NAME}-{BALL_DETECTOR_MODEL_NAME}-{datetime.now()}\", spawn=True\n",
    ")  # Spawn a Rerun Viewer and stream log events to it\n",
    "\n",
    "colours_per_idx = defaultdict(lambda: (255, 255, 255))\n",
    "colours_per_idx.update(\n",
    "    {\n",
    "        0: (0, 255, 0),\n",
    "        1: (0, 0, 255),\n",
    "        2: (255, 0, 0),\n",
    "        3: (255, 255, 0),\n",
    "        4: (255, 0, 255),\n",
    "        5: (0, 255, 255),\n",
    "    }\n",
    ")\n",
    "rr.set_time_sequence(\"play\", 0)\n",
    "log_court_layout(\n",
    "    camera_matrix=np.load(CALIBRATION_FILE)[\"camera_matrix\"],\n",
    "    image_width=results[0].orig_img.shape[1],\n",
    "    image_height=results[0].orig_img.shape[0],\n",
    "    court_mesh_path=COURT_MESH_PATH,\n",
    "    translation_vector=np.load(CALIBRATION_FILE)[\"translation_vector\"],\n",
    "    rotation_vector=np.load(CALIBRATION_FILE)[\"rotation_vector\"],\n",
    ")\n",
    "H = np.load(IMAGE_TO_FLOOR_HOMOGRAPHY_FILE)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    # Start streaming results to the Rerun Viewer\n",
    "    rr.set_time_sequence(\"play\", i)\n",
    "    if RUN_BALL_DETECTION:\n",
    "        with torch.no_grad():\n",
    "            outputs = ball_detector(\n",
    "                image_to_tensor(result.orig_img, keepdim=False).float() / 255.0,\n",
    "            )\n",
    "        ball_detection_resullt.append(outputs)\n",
    "        dump(ball_detection_resullt, open(\"ball_detection_resullt.pkl\", \"wb\"))\n",
    "    else:\n",
    "        outputs = ball_detection_resullt[i]\n",
    "\n",
    "    if outputs and len(outputs[0][\"boxes\"]) > 0:\n",
    "        for output in outputs:\n",
    "            for (bx1, by1, bx2, by2), ball_score in zip(\n",
    "                output[\"boxes\"][:4], output[\"scores\"]\n",
    "            ):\n",
    "                # bx1, by1, bx2, by2 = outputs[0][\"boxes\"][0]\n",
    "                if bx1 < 200 or bx2 < 200:\n",
    "                    continue\n",
    "                rr.log_rect(\n",
    "                    f\"world/camera/image/Ball\",\n",
    "                    (bx1, by1, bx2 - bx1, by2 - by1),\n",
    "                    color=colours_per_idx[-1],\n",
    "                )\n",
    "                # Ball Tracker Goes here!!\n",
    "                if RUN_BALL_TRACKER:\n",
    "                    obs_state = torch.tensor(\n",
    "                        [\n",
    "                            (bx1 + bx2) / 2.0,\n",
    "                            (by1 + by2) / 2.0,\n",
    "                        ]\n",
    "                    ).to(dtype=torch.float32)\n",
    "                    xyz = tracker.xyz.clone()\n",
    "                    xyz[:, StateIdx.y] = 200.0 - xyz[:, StateIdx.y]\n",
    "                    rr.log_points(\n",
    "                        \"world/ball_state\",\n",
    "                        positions=tracker.xyz,\n",
    "                    )\n",
    "                    rr.log_point(\n",
    "                        \"world/tracker_mean\",\n",
    "                        tracker.xyz_mean,\n",
    "                        color=(255, 222, 0),\n",
    "                        radius=2.0,\n",
    "                    )\n",
    "                    for _ in range(10):\n",
    "                        tracker.predict(dt=1 / 30.0)\n",
    "                        tracker.update(obs_state=obs_state, score=ball_score)\n",
    "\n",
    "                    # Check Tracker and Vis agree on transforms\n",
    "                    tracker_points = tracker.state_to_observation(\n",
    "                        tracker.states,\n",
    "                        world_to_cam=tracker.world_to_cam,\n",
    "                        cam_to_image=tracker.cam_to_image,\n",
    "                    )\n",
    "                    tracker_mean = tracker.state_to_observation(\n",
    "                        tracker.xyz_mean,\n",
    "                        world_to_cam=tracker.world_to_cam,\n",
    "                        cam_to_image=tracker.cam_to_image,\n",
    "                    )\n",
    "                    rr.log_points(\"world/camera/image/tracker\", tracker_points)\n",
    "                    rr.log_point(\n",
    "                        \"world/camera/image/tracker/mean\",\n",
    "                        tracker_mean,\n",
    "                        radius=10.0,\n",
    "                        color=(255, 222, 0),\n",
    "                    )\n",
    "\n",
    "    rr.log_image(\"world/camera/image\", result.orig_img)\n",
    "\n",
    "    for det in result.boxes.data:\n",
    "        x1, y1, x2, y2, idx, conf, cls = det\n",
    "        rr.log_rect(\n",
    "            f\"world/camera/image/Player_{int(idx)}\",\n",
    "            (x1, y1, (x2 - x1), (y2 - y1)),\n",
    "            color=colours_per_idx[int(idx)],\n",
    "        )\n",
    "        mid_feet = torch.tensor([((x1 + x2) / 2, (y2 + y2) / 2)])\n",
    "        (mid_feet_base,) = project_points_to_base_plane(points=mid_feet, H=H)\n",
    "\n",
    "        mid_feet_base_3d = (\n",
    "            F.pad(mid_feet_base, (0, 1), mode=\"constant\", value=0.0) / 10.0\n",
    "        )\n",
    "        # Switch Y and Z axis\n",
    "        x = mid_feet_base_3d[0].item()\n",
    "        y = mid_feet_base_3d[1].item()\n",
    "        z = mid_feet_base_3d[2].item()\n",
    "        mid_feet_base_3d[2] = player_maker_radius\n",
    "        mid_feet_base_3d[1] = 200.0 - y\n",
    "        mid_feet_base_3d[0] = x\n",
    "        rr.log_point(\n",
    "            f\"world/Player_{int(idx)}\",\n",
    "            mid_feet_base_3d,\n",
    "            radius=player_maker_radius,\n",
    "            color=colours_per_idx[int(idx)],\n",
    "        )\n",
    "\n",
    "        # base_results[f\"{int(idx)}_xs\"].append(mid_feet_base[0].item())\n",
    "        # base_results[f\"{int(idx)}_ys\"].append(mid_feet_base[1].item())\n",
    "        # base_results[f\"{int(idx)}_zs\"].append(0.0)\n",
    "        # base_results[f\"{int(idx)}_conf\"].append(conf.item())\n",
    "\n",
    "    # if i > 10:\n",
    "    #     break\n",
    "\n",
    "    # break\n",
    "# plt.imshow(image)\n",
    "# results[0].boxes.boxes, results[0].boxes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>dd = torch.tensor([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>])                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 # F.pad(dd, ( 0,1), mode=\"constant\", value=0.0)</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 # swap y and z</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4 torch.swapdims(dd, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>dd                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>Dimension out of range <span style=\"font-weight: bold\">(</span>expected to be in range of <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, but got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mdd = torch.tensor([\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m3\u001b[0m])                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m# F.pad(dd, ( 0,1), mode=\"constant\", value=0.0)\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m\u001b[2m# swap y and z\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4 torch.swapdims(dd, \u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0mdd                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndexError: \u001b[0mDimension out of range \u001b[1m(\u001b[0mexpected to be in range of \u001b[1m[\u001b[0m\u001b[1;36m-1\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, but got \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = torch.tensor([1, 2, 3])\n",
    "# F.pad(dd, ( 0,1), mode=\"constant\", value=0.0)\n",
    "# swap y and z\n",
    "torch.swapdims(dd, 1, 2)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[603.8484, 189.4671, 612.9427, 194.0199],\n",
       "          [131.2941,  79.5147, 144.1550,  90.2277],\n",
       "          [604.2704, 188.3363, 611.2602, 192.5852],\n",
       "          [604.0818, 190.9785, 613.0499, 195.5561]]),\n",
       "  'labels': tensor([1, 1, 1, 1]),\n",
       "  'scores': tensor([0.9173, 0.3210, 0.3151, 0.2348])}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball_detection_resullt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_court_frontwall_markings():\n",
    "    outer_lines = np.array(\n",
    "        [\n",
    "            # Outer lines\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "            corners_world_3d[\"b_front_right\"],\n",
    "            corners_world_3d[\"n_top_front_right\"],\n",
    "            corners_world_3d[\"m_top_front_left\"],\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    x_offset = 3 * 100.0\n",
    "    z_offset = 5 * 100.0\n",
    "    play_boundary = np.array(\n",
    "        [\n",
    "            # Outer lines\n",
    "            (\n",
    "                corners_world_3d[\"a_front_left\"][0] - x_offset,\n",
    "                corners_world_3d[\"a_front_left\"][1],\n",
    "                corners_world_3d[\"a_front_left\"][2],\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"b_front_right\"][0] + x_offset,\n",
    "                corners_world_3d[\"b_front_right\"][1],\n",
    "                corners_world_3d[\"b_front_right\"][2],\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"n_top_front_right\"][0] + x_offset,\n",
    "                corners_world_3d[\"n_top_front_right\"][1],\n",
    "                corners_world_3d[\"n_top_front_right\"][2] + z_offset,\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"m_top_front_left\"][0] - x_offset,\n",
    "                corners_world_3d[\"m_top_front_left\"][1],\n",
    "                corners_world_3d[\"m_top_front_left\"][2] + z_offset,\n",
    "            ),\n",
    "            (\n",
    "                corners_world_3d[\"a_front_left\"][0] - x_offset,\n",
    "                corners_world_3d[\"a_front_left\"][1],\n",
    "                corners_world_3d[\"a_front_left\"][2],\n",
    "            ),\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    xs = np.array([outer_lines[:-1, 0], outer_lines[1:, 0]]).T\n",
    "    xs = np.append(\n",
    "        xs, np.array([play_boundary[:-1, 0], play_boundary[1:, 0]]).T, axis=0\n",
    "    )\n",
    "\n",
    "    ys = np.array([outer_lines[:-1, 1], outer_lines[1:, 1]]).T\n",
    "    ys = np.append(\n",
    "        ys, np.array([play_boundary[:-1, 1], play_boundary[1:, 1]]).T, axis=0\n",
    "    )\n",
    "\n",
    "    zs = np.array([outer_lines[:-1, 2], outer_lines[1:, 2]]).T\n",
    "    zs = np.append(\n",
    "        zs, np.array([play_boundary[:-1, 2], play_boundary[1:, 2]]).T, axis=0\n",
    "    )\n",
    "\n",
    "    return xs, ys, zs\n",
    "\n",
    "\n",
    "xs, ys, zs = get_court_frontwall_markings()\n",
    "plt_axis, fig = plot_3d_lines(xs=xs, ys=ys, zs=zs, view_init=(0, 90, 0))\n",
    "plt_axis.set_title(\"\")\n",
    "plt_axis.set_xlabel(\"\")\n",
    "plt_axis.set_ylabel(\"\")\n",
    "plt_axis.set_xticks([])\n",
    "plt_axis.set_yticks([])\n",
    "plt_axis.set_zticks([])\n",
    "plt_axis.spines[\"right\"].set_visible(False)\n",
    "plt_axis.spines[\"top\"].set_visible(False)\n",
    "plt_axis.spines[\"bottom\"].set_visible(False)\n",
    "plt_axis.spines[\"left\"].set_visible(False)\n",
    "plt.axis(\"off\")\n",
    "plt.axis(\"image\")\n",
    "plt.savefig(\"frontwall.png\", bbox_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_world_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_court_markings():\n",
    "    outer_lines = np.array(\n",
    "        [\n",
    "            # Outer lines\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "            corners_world_3d[\"b_front_right\"],\n",
    "            corners_world_3d[\"d_back_right\"],\n",
    "            corners_world_3d[\"c_back_left\"],\n",
    "            corners_world_3d[\"a_front_left\"],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    inner_lines = np.array(\n",
    "        [\n",
    "            corners_world_3d[\"e_left_near_serve_line\"],\n",
    "            corners_world_3d[\"f_right_near_serve_line\"],\n",
    "            corners_world_3d[\"h_right_far_serve_line\"],\n",
    "            corners_world_3d[\"g_left_far_serve_line\"],\n",
    "            corners_world_3d[\"e_left_near_serve_line\"],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    center_line = np.array(\n",
    "        [\n",
    "            corners_world_3d[\"k_center_line_near\"],\n",
    "            corners_world_3d[\"i_center_line_far\"],\n",
    "        ]\n",
    "    )\n",
    "    net_line = np.array(\n",
    "        [\n",
    "            corners_world_3d[\"j_net_line_left\"],\n",
    "            corners_world_3d[\"l_net_line_right\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    xs = np.array([outer_lines[:-1, 0], outer_lines[1:, 0]]).T\n",
    "    xs = np.append(xs, np.array([inner_lines[:-1, 0], inner_lines[1:, 0]]).T, axis=0)\n",
    "    xs = np.append(xs, np.array([center_line[:-1, 0], center_line[1:, 0]]).T, axis=0)\n",
    "    xs = np.append(xs, np.array([net_line[:-1, 0], net_line[1:, 0]]).T, axis=0)\n",
    "\n",
    "    ys = np.array([outer_lines[:-1, 1], outer_lines[1:, 1]]).T\n",
    "    ys = np.append(ys, np.array([inner_lines[:-1, 1], inner_lines[1:, 1]]).T, axis=0)\n",
    "    ys = np.append(ys, np.array([center_line[:-1, 1], center_line[1:, 1]]).T, axis=0)\n",
    "    ys = np.append(ys, np.array([net_line[:-1, 1], net_line[1:, 1]]).T, axis=0)\n",
    "\n",
    "    zs = np.array([outer_lines[:-1, 2], outer_lines[1:, 2]]).T\n",
    "    zs = np.append(zs, np.array([inner_lines[:-1, 2], inner_lines[1:, 2]]).T, axis=0)\n",
    "    zs = np.append(zs, np.array([center_line[:-1, 2], center_line[1:, 2]]).T, axis=0)\n",
    "    zs = np.append(zs, np.array([net_line[:-1, 2], net_line[1:, 2]]).T, axis=0)\n",
    "\n",
    "    return xs, ys, zs\n",
    "\n",
    "\n",
    "xs, ys, zs = get_court_markings()\n",
    "plt_axis, fig = plot_3d_lines(xs=xs, ys=ys, zs=zs, view_init=(90, 90, 0))\n",
    "from courtvision.vis import plot_3d_points\n",
    "\n",
    "idx = 1\n",
    "# xs = np.array(base_results[f\"{idx}_xs\"])\n",
    "# ys = np.array(base_results[f\"{idx}_ys\"])\n",
    "# zs = np.array(base_results[f\"{idx}_zs\"])\n",
    "plt_axis.set_title(\"\")\n",
    "plt_axis.set_xlabel(\"\")\n",
    "plt_axis.set_ylabel(\"\")\n",
    "plt_axis.set_xticks([])\n",
    "plt_axis.set_yticks([])\n",
    "plt_axis.set_zticks([])\n",
    "plt_axis.spines[\"right\"].set_visible(False)\n",
    "plt_axis.spines[\"top\"].set_visible(False)\n",
    "plt_axis.spines[\"bottom\"].set_visible(False)\n",
    "plt_axis.spines[\"left\"].set_visible(False)\n",
    "# plot_3d_lines\n",
    "plt.axis(\"off\")\n",
    "plt.axis(\"image\")\n",
    "plt_axis.margins(x=0)\n",
    "plt.savefig(\"test.png\", bbox_inches=0)\n",
    "\n",
    "# plt_axis, _=plot_3d_points(x=xs, y=ys, z=zs, plt_axis=plt_axis ,view_init=(90, 90,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.log(\"test\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from courtvision.vis import plot_3d_points, plot_3d_lines\n",
    "from courtvision.geometry import get_coords_world_3d\n",
    "import numpy as np\n",
    "\n",
    "court_markings = get_coords_world_3d()\n",
    "xs = np.array([court_markings[:1, 0], court_markings[1:2, 0]]).T\n",
    "xs = np.append(xs, np.array([court_markings[1:2, 0], court_markings[3:4, 0]]).T, axis=0)\n",
    "xs = np.append(xs, np.array([court_markings[3:4, 0], court_markings[4:5, 0]]).T, axis=0)\n",
    "xs = np.append(xs, np.array([court_markings[4:5, 0], court_markings[:1, 0]]).T, axis=0)\n",
    "\n",
    "ys = np.array([court_markings[:-1, 1], court_markings[1:, 1]]).T\n",
    "zs = np.array([court_markings[:-1, 2], court_markings[1:, 2]]).T\n",
    "plot_3d_lines(xs=xs, ys=ys, zs=zs)\n",
    "# get_coords_world_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
